{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import torch\n",
    "from scvi.model import SCVI, CondSCVI\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from destvi_spatial import DestVISpatial\n",
    "\n",
    "scvi.settings.reset_logging_handler()\n",
    "import logging\n",
    "\n",
    "sys.path.append(\"/data/yosef2/users/pierreboyeau/DestVI-reproducibility/simulations\")\n",
    "from utils import (find_location_index_cell_type, get_mean_normal,\n",
    "                   metrics_vector)\n",
    "\n",
    "logger = logging.getLogger(\"scvi\")\n",
    "\n",
    "\n",
    "def construct_neighboors(adata, n_neighbors=5):\n",
    "    locs = adata.obsm[\"locations\"]\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"ball_tree\").fit(locs)\n",
    "    idx_to_neighs = nbrs.kneighbors(locs)[1][:, 1:]\n",
    "    n_indices_ = torch.tensor(idx_to_neighs)\n",
    "    X = torch.tensor(adata.X.todense())\n",
    "    X_neigh = X[n_indices_]\n",
    "    return X_neigh.numpy(), n_indices_.numpy()\n",
    "\n",
    "\n",
    "def construct_spatial_partition(adata, n_cv=5):\n",
    "    locs = adata.obsm[\"locations\"]\n",
    "    clust = KMeans(n_clusters=n_cv, n_init=100)\n",
    "    attribs = clust.fit_predict(locs)\n",
    "    return attribs\n",
    "\n",
    "\n",
    "WORKING_DIR = \"/data/yosef2/users/pierreboyeau/scvi-tools/simulations_code\"\n",
    "input_dir = os.path.join(WORKING_DIR, \"out/\")\n",
    "output_suffix = \"destvi\"\n",
    "sc_epochs = 250\n",
    "st_epochs = 250\n",
    "# sc_epochs = 2\n",
    "# st_epochs = 2\n",
    "amortization = \"latent\"\n",
    "\n",
    "sc_adata = sc.read_h5ad(input_dir + \"sc_simu.h5ad\")\n",
    "st_adata = sc.read_h5ad(input_dir + \"st_simu.h5ad\")\n",
    "\n",
    "logger.info(\"Running DestVI\")\n",
    "\n",
    "output_dir = input_dir + output_suffix + \"_\" + amortization + \"/\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    logger.info(\"Directory doesn't exist, creating it\")\n",
    "    os.mkdir(output_dir)\n",
    "else:\n",
    "    logger.info(f\"Found directory at:{output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "def destvi_get_metrics(spatial_model):\n",
    "    # second get the proportion estimates\n",
    "    proportions = spatial_model.get_proportions().values\n",
    "    agg_prop_estimates = proportions\n",
    "\n",
    "    # third impute at required locations\n",
    "    # for each cell type, query the model at certain locations and compare to groundtruth\n",
    "    # create a global flush for comparaison across cell types\n",
    "    imputed_expression = np.zeros_like(s_groundtruth)\n",
    "    for ct in range(C):\n",
    "        indices, _ = find_location_index_cell_type(\n",
    "            st_adata.obsm[\"locations\"], ct, s_location, s_ct\n",
    "        )\n",
    "        expression = spatial_model.get_scale_for_ct(\n",
    "            spatial_model.cell_type_mapping[ct], indices=indices\n",
    "        ).values\n",
    "        normalized_expression = expression / np.sum(expression, axis=1)[:, np.newaxis]\n",
    "        # flush to global\n",
    "        indices_gt = np.where(s_ct == ct)[0]\n",
    "        imputed_expression[indices_gt] = normalized_expression\n",
    "    all_res = []\n",
    "    all_res_long = []\n",
    "    for ct in range(C):\n",
    "        # get local scores\n",
    "        indices_gt = np.where(s_ct == ct)[0]\n",
    "        # potentially filter genes for local scores only\n",
    "        gene_list = np.unique(\n",
    "            np.hstack([np.where(components_[ct, i] != 0)[0] for i in range(D)])\n",
    "        )\n",
    "        res = metrics_vector(\n",
    "            s_groundtruth[indices_gt],\n",
    "            imputed_expression[indices_gt],\n",
    "            scaling=2e5,\n",
    "            feature_shortlist=gene_list,\n",
    "        )\n",
    "        res_long = metrics_vector(\n",
    "            s_groundtruth[indices_gt], imputed_expression[indices_gt], scaling=2e5\n",
    "        )\n",
    "        all_res.append(pd.Series(res))\n",
    "        all_res_long.append(pd.Series(res_long))\n",
    "    all_res.append(\n",
    "        pd.Series(metrics_vector(s_groundtruth, imputed_expression, scaling=2e5))\n",
    "    )\n",
    "    all_res = all_res + all_res_long\n",
    "    df = pd.concat(all_res, axis=1)\n",
    "    prop_score = metrics_vector(st_adata.obsm[\"cell_type\"], agg_prop_estimates)\n",
    "    df = pd.concat([df, pd.Series(prop_score)], axis=1)\n",
    "    df.columns = (\n",
    "        [\"ct\" + str(i) for i in range(5)]\n",
    "        + [\"ct_long\" + str(i) for i in range(5)]\n",
    "        + [\"allct\", \"proportions\"]\n",
    "    )\n",
    "    return df.T.reset_index().rename(columns=dict(index=\"where_ct\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training single-cell model & gathering spot neighborhood information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup ann data\n",
    "scvi.data.setup_anndata(sc_adata, labels_key=\"cell_type\")\n",
    "mapping = sc_adata.uns[\"_scvi\"][\"categorical_mappings\"][\"_scvi_labels\"][\"mapping\"]\n",
    "\n",
    "# train sc-model\n",
    "sc_model = CondSCVI(sc_adata, n_latent=4, n_layers=2, n_hidden=128)\n",
    "sc_model.train(\n",
    "    max_epochs=sc_epochs,\n",
    "    plan_kwargs={\"n_epochs_kl_warmup\": 2},\n",
    "    progress_bar_refresh_rate=1,\n",
    ")\n",
    "plt.plot(sc_model.history[\"elbo_train\"], label=\"train\")\n",
    "plt.title(\"ELBO on train set over training epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(output_dir + \"sc_model_training.png\")\n",
    "plt.clf()\n",
    "_sc_model = copy.deepcopy(sc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n, ind_n = construct_neighboors(st_adata, n_neighbors=5)\n",
    "attribs = construct_spatial_partition(st_adata)\n",
    "st_adata.obsm[\"x_n\"] = x_n\n",
    "st_adata.obsm[\"ind_n\"] = ind_n\n",
    "scvi.data.setup_anndata(st_adata)\n",
    "\n",
    "amortization = \"latent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = pd.DataFrame(st_adata.obsm[\"locations\"])\n",
    "loc_df.columns = [\"x\", \"y\"]\n",
    "loc_df = (\n",
    "    loc_df\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"spot\"})\n",
    ")\n",
    "\n",
    "gt_props = pd.DataFrame(st_adata.obsm[\"cell_type\"])\n",
    "gt_props.columns = [\"ct0\", \"ct1\", \"ct2\", \"ct3\", \"ct4\"]\n",
    "gt_props = (\n",
    "    gt_props\n",
    "    .stack()\n",
    "    .to_frame(\"proportion_gt\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"spot\", \"level_1\": \"celltype\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_indices = [1, 25, 100, 1000]\n",
    "plt.scatter(st_adata.obsm[\"locations\"][rdm_indices, 0], st_adata.obsm[\"locations\"][rdm_indices, 1])\n",
    "n_locs = st_adata.obsm[\"locations\"][st_adata.obsm[\"ind_n\"][rdm_indices]].reshape(-1, 2)\n",
    "plt.scatter(n_locs[:, 0], n_locs[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: get ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = \"/data/yosef2/users/pierreboyeau/data/spatial_data/\"\n",
    "PCA_path = param_path + \"grtruth_PCA.npz\"\n",
    "grtruth_PCA = np.load(PCA_path)\n",
    "mean_, components_ = grtruth_PCA[\"mean_\"], grtruth_PCA[\"components_\"]\n",
    "\n",
    "C = components_.shape[0]\n",
    "D = components_.shape[1]\n",
    "\n",
    "threshold_gt = 0.4\n",
    "spot_selection = np.where(st_adata.obsm[\"cell_type\"].max(1) > threshold_gt)[0]\n",
    "s_location = st_adata.obsm[\"locations\"][spot_selection]\n",
    "s_ct = st_adata.obsm[\"cell_type\"][spot_selection, :].argmax(1)\n",
    "s_gamma = st_adata.obsm[\"gamma\"][spot_selection]\n",
    "s_groundtruth = get_mean_normal(s_ct[:, None], s_gamma[:, None], mean_, components_)[:, 0, :]\n",
    "s_groundtruth[s_groundtruth < 0] = 0\n",
    "s_groundtruth = np.expm1(s_groundtruth)\n",
    "s_groundtruth = s_groundtruth / np.sum(s_groundtruth, axis=1)[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: estimate GT $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lamb_scales = np.geomspace(1e3, 1e9, 50)\n",
    "\n",
    "WORKING_DIRB = os.path.join(WORKING_DIR, \"mdl_ckpt2\")\n",
    "\n",
    "gridsearch_res = pd.DataFrame()\n",
    "gridsearch_metrics_res = pd.DataFrame()\n",
    "for lamb in lamb_scales:\n",
    "    for seed in range(3):\n",
    "    # for seed in range(1):\n",
    "        for n_neig in [3, 5]:\n",
    "            for mode in [\"pair\"]:\n",
    "                save_feat = [lamb, n_neig, seed]\n",
    "                save_feat = [str(sv) for sv in save_feat]\n",
    "                savename = \"_\".join(save_feat) + \"nn_step1_25pts.pt\"\n",
    "                mdl_path = os.path.join(WORKING_DIRB, savename)\n",
    "                x_n, ind_n = construct_neighboors(st_adata, n_neighbors=n_neig)\n",
    "                attribs = construct_spatial_partition(st_adata)\n",
    "                st_adata.obsm[\"x_n\"] = x_n\n",
    "                st_adata.obsm[\"ind_n\"] = ind_n\n",
    "                scvi.data.setup_anndata(st_adata)\n",
    "                print(x_n.shape)\n",
    "\n",
    "                if os.path.exists(mdl_path):\n",
    "                    print(\"Model exists ...\")\n",
    "                    spatial_model_prior = DestVISpatial.load(mdl_path, st_adata)\n",
    "                else:\n",
    "                    print(\"Model does not exists ...\")\n",
    "                    spatial_model_prior = DestVISpatial.from_rna_model(\n",
    "                        st_adata,\n",
    "                        sc_model,\n",
    "                        vamp_prior_p=100,\n",
    "                        amortization=amortization,\n",
    "                        spatial_prior=True, \n",
    "                        spatial_agg=mode,\n",
    "                        lamb=lamb,\n",
    "                    )\n",
    "                    spatial_model_prior.train(\n",
    "                        max_epochs=2000,\n",
    "                        # max_epochs=2,\n",
    "                        train_size=1,\n",
    "                        lr=1e-2, \n",
    "                        n_epochs_kl_warmup=400,\n",
    "                        progress_bar_refresh_rate=0,\n",
    "                    )\n",
    "                    spatial_model_prior.save(mdl_path)\n",
    "                df = destvi_get_metrics(spatial_model_prior)\n",
    "                props_all_metrics = (\n",
    "                    df\n",
    "                    .assign(\n",
    "                        Model=mode,\n",
    "                        lamb=lamb,\n",
    "                        n_neig=n_neig,\n",
    "                        seed=seed,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                gridsearch_metrics_res = (\n",
    "                    gridsearch_metrics_res.append(props_all_metrics, ignore_index=True)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_model_gt = DestVISpatial.from_rna_model(\n",
    "    st_adata,\n",
    "    _sc_model,\n",
    "    vamp_prior_p=100,\n",
    "    amortization=amortization,\n",
    "    spatial_prior=False,\n",
    ")\n",
    "spatial_model_gt.train(\n",
    "    max_epochs=1000,\n",
    "    # max_epochs=2,\n",
    "    train_size=1,\n",
    "    lr=1e-1, \n",
    "    n_epochs_kl_warmup=100,\n",
    "    progress_bar_refresh_rate=1,\n",
    ")\n",
    "\n",
    "\n",
    "df = destvi_get_metrics(spatial_model_gt)\n",
    "props_all_metrics = (\n",
    "    df\n",
    "    .assign(\n",
    "        Model=mode,\n",
    "        lamb=-np.infty,\n",
    "        n_neig=n_neig,\n",
    "    )\n",
    ")\n",
    "gridsearch_metrics_res = gridsearch_metrics_res.append(props_all_metrics, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gt_df = gridsearch_metrics_res.sort_values(\"lamb\").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Gene CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelim: Try to find gene modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = sc_model.get_normalized_expression()\n",
    "\n",
    "cts = sc_model.adata.obs[\"cell_type\"]\n",
    "\n",
    "scvi_model = SCVI(sc_adata, n_latent=2, n_layers=2, n_hidden=128)\n",
    "scvi_model.train(\n",
    "    max_epochs=sc_epochs,\n",
    "    plan_kwargs={\"n_epochs_kl_warmup\": 2},\n",
    "    progress_bar_refresh_rate=1,\n",
    ")\n",
    "\n",
    "latent = scvi_model.get_latent_representation()\n",
    "\n",
    "latent_ = pd.DataFrame(latent)\n",
    "latent_.index = [\"cell\" + str(col) for col in latent_.index]\n",
    "expression_ = expression.T\n",
    "expression_.columns = [\"cell\"+ str(col) for col in expression_.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hotspot\n",
    "hs = hotspot.Hotspot(expression_, model='none', latent=latent_)\n",
    "\n",
    "hs.create_knn_graph(weighted_graph=False, n_neighbors=30)\n",
    "hs_results = hs.compute_autocorrelations()\n",
    "\n",
    "# hs_genes = hs_results.loc[hs_results.FDR < 0.05].index # Select genes\n",
    "hs_genes = hs_results.index\n",
    "local_correlations = hs.compute_local_correlations(hs_genes, jobs=20) # jobs for parallelization\n",
    "\n",
    "modules = hs.create_modules(\n",
    "    min_gene_threshold=30, core_only=False, fdr_threshold=0.05\n",
    ")\n",
    "gene_train_indices = (\n",
    "    modules\n",
    "    .groupby(modules)\n",
    "    .apply(lambda x: x.sample(frac=0.5).index.to_series().astype(int))\n",
    "    .to_frame(\"indices\")\n",
    "    .reset_index()\n",
    "    .indices\n",
    "    .values\n",
    ")\n",
    "\n",
    "nfolds = 2\n",
    "ngenes = st_adata.X.shape[-1]\n",
    "heldout_folds = np.arange(nfolds)\n",
    "gene_folds = np.isin(np.arange(ngenes), gene_train_indices)\n",
    "\n",
    "\n",
    "for heldout in heldout_folds[:-1]:\n",
    "    training_mask = gene_folds != heldout\n",
    "    training_mask = torch.tensor(training_mask)\n",
    "    test_mask = ~training_mask\n",
    "    print(training_mask.sum(), test_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_epochs = 500\n",
    "cv_results_metrics = pd.DataFrame()\n",
    "for heldout in heldout_folds[:-1]:\n",
    "    training_mask = gene_folds != heldout\n",
    "    training_mask = torch.tensor(training_mask)\n",
    "    test_mask = ~training_mask\n",
    "    for lamb in lamb_scales:\n",
    "        save_feat = [lamb, n_neig, heldout]\n",
    "        save_feat = [str(sv) for sv in save_feat]\n",
    "        savename = \"_\".join(save_feat) + \"_step2_25pts_500___1epcs_stratified.pt\"\n",
    "        \n",
    "        \n",
    "        mdl_path = os.path.join(WORKING_DIRB, savename)\n",
    "        if os.path.exists(mdl_path):\n",
    "            spatial_model = DestVISpatial.load(mdl_path, st_adata)\n",
    "            spatial_model.construct_loaders()\n",
    "        else:\n",
    "            spatial_model = DestVISpatial.from_rna_model(\n",
    "                st_adata,\n",
    "                sc_model,\n",
    "                vamp_prior_p=100,\n",
    "                amortization=amortization,\n",
    "                spatial_prior=True,\n",
    "                spatial_agg=\"pair\",\n",
    "                lamb=lamb,\n",
    "                training_mask=training_mask,\n",
    "            )\n",
    "\n",
    "            # Step 1: training genes\n",
    "            spatial_model.train(\n",
    "                max_epochs=1000,\n",
    "                # max_epochs=2,\n",
    "                train_size=1,\n",
    "                lr=1e-2, \n",
    "                n_epochs_kl_warmup=400,\n",
    "                plan_kwargs=dict(\n",
    "                    loss_mask=training_mask,\n",
    "                ),\n",
    "                progress_bar_refresh_rate=1,\n",
    "            )\n",
    "\n",
    "            # Step 2: heldout genes\n",
    "            myparameters = [spatial_model.module.eta] + [spatial_model.module.beta]\n",
    "            myparameters = filter(lambda p: p.requires_grad, myparameters)\n",
    "            spatial_model.train(\n",
    "                max_epochs=st_epochs,\n",
    "                # max_epochs=2,\n",
    "                train_size=1,\n",
    "                progress_bar_refresh_rate=1,\n",
    "                n_epochs_kl_warmup=400,\n",
    "                lr=1e-2, \n",
    "                plan_kwargs=dict(\n",
    "                    loss_mask=test_mask, \n",
    "                    myparameters=myparameters,\n",
    "                ),\n",
    "            )\n",
    "            spatial_model.save(mdl_path)    \n",
    "        rec_loss, rec_loss_all = spatial_model.get_metric()\n",
    "        gene_infos = pd.DataFrame(\n",
    "            {\n",
    "                \"gene\": [\"full\"] + list(np.arange(len(rec_loss_all))),\n",
    "                \"reconstruction\": [rec_loss] + list(rec_loss_all)\n",
    "            }\n",
    "        ).assign(\n",
    "            heldout=heldout,\n",
    "            lamb=lamb,\n",
    "            train_phase=False\n",
    "        )\n",
    "        cv_results_metrics = cv_results_metrics.append(gene_infos, ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verifying properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_val = (\n",
    "    validation_gt_df\n",
    "    .assign(lambdd=lambda x: np.log10(x.lamb))\n",
    "    .assign(lambdd=lambda x: x.lambdd.fillna(0.))\n",
    "#     .loc[lambda x: x.Model == \"pair\"]\n",
    "    .loc[lambda x: x.where_ct == \"proportions\"]\n",
    "    .loc[lambda x: x.n_neig == 5]\n",
    "    .groupby([\"lambdd\", \"n_neig\", \"Model\", \"where_ct\"])\n",
    "    [\"avg_spearman\", \"avg_pearson\", \"median_l1\", \"mse\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plot_df_cv = (\n",
    "    cv_results_metrics\n",
    "    .loc[lambda x: x.gene != \"full\"]\n",
    "    .assign(lambdd=lambda x: np.log10(x.lamb))\n",
    "    .groupby(\"lambdd\")\n",
    "    .reconstruction\n",
    "#     .median()\n",
    "    .max()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_name = \"avg_spearman\"\n",
    "orac_name = \"reconstruction\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_met = plot_df_val.iloc[0][met_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['ps.useafm'] = True\n",
    "plt.rcParams['pdf.use14corefonts'] = True\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, sharex=True, figsize=(4, 3))\n",
    "plt.plot(\n",
    "    plot_df_val.iloc[1:].lambdd, \n",
    "    plot_df_val.iloc[1:][met_name],\n",
    "    c=\"blue\"\n",
    ")\n",
    "lambdstar = plot_df_val.iloc[1:][met_name]\n",
    "xmin, xmax = plt.xlim()\n",
    "orac = plot_df_val.iloc[1:].set_index(\"lambdd\")[met_name]\n",
    "lambdstar = orac.idxmax()\n",
    "corrmax = orac.max()\n",
    "plt.hlines(ref_met, xmin, xmax, color=\"black\")\n",
    "plt.ylabel(\"Mean proportions correlation\", c=\"blue\")\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.locator_params(axis='y', nbins=5)\n",
    "plt.vlines(lambdstar, ymin, corrmax, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.twinx()\n",
    "plt.plot(plot_df_cv.lambdd, plot_df_cv[orac_name], c=\"red\")\n",
    "lambda_best = plot_df_cv.set_index(\"lambdd\").reconstruction.idxmin()\n",
    "reco_best = plot_df_cv.set_index(\"lambdd\").reconstruction.min()\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(lambda_best, ymin, reco_best, color=\"black\", linestyle=\"--\")\n",
    "# plt.ylim(ymin, 25000)\n",
    "# plt.ylim(ymin, 1800)\n",
    "plt.ylabel(\"Heldout reconstruction error\", c=\"red\")\n",
    "plt.xlabel(\"Prior strenght\")\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "\n",
    "ticks = [4, 8, lambda_best, lambdstar]\n",
    "labels = [\n",
    "    4, \n",
    "    8, \n",
    "    \"$\\hat \\lambda \\approx$ {:.2f}\".format(lambda_best),\n",
    "    \"$\\lambda\\^ \\star \\approx$ {:.2f}\".format(lambdstar)\n",
    "]\n",
    "plt.xticks(ticks, labels)\n",
    "# plt.xticks(list(plt.xticks()[0]) + [lambda_best])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"spatialprior.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('destvi6': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd03bd2149aa6a341eedb3a9eb095b979da659a384dbf906944988d3bc2d662ed97"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "3bd2149aa6a341eedb3a9eb095b979da659a384dbf906944988d3bc2d662ed97"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
